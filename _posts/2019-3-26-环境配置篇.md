# 环境配置篇

完整的`/etc/profile`文件：

```shell
# set java environment
JAVA_HOME=/usr/java/jdk1.8.0_201
JRE_HOME=/usr/java/jdk1.8.0_201/jre
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
export JAVA_HOME JRE_HOME CLASSPATH PATH

# set flink environment
export FLINK_HOME=/usr/local/flink/flink-1.7.2
export PATH=$PATH:$FLINK_HOME/bin

# set maven environment
export M2_HOME=/opt/maven
export CLASSPATH=$CLASSPATH:$M2_HOME/lib
export PATH=$PATH:$M2_HOME/bin

# set hadoop environment
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# set hbase environment
export HBASE_HOME=/usr/local/hbase-1.3.3
export PATH=$PATH:$HBASE_HOME/bin

# set zookeeper environment
export ZOOKEEPER_HOME=/usr/local/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME/bin

# set kafka environment
export KAFKA_HOME=/usr/local/kafka
export PATH=$PATH:$KAFKA_HOME/bin
```



## 1. Java

首先解压Java文件到`/usr/java`目录下

```sh
sudo tar -zxvf jdk-8u201-linux-x64.tar.gz -C /usr/java
```

加入环境变量，在`/etc/profile`文件中加入Java的PATH：

```shell
# set java environment
export JAVA_HOME=/usr/java/jdk1.8.0_201
export JRE_HOME=/usr/java/jdk1.8.0_201/jre
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
```

刷新当前环境，或重启计算机：

```shell
source /etc/profile
```

## 2. Hadoop

首先解压Hadoop文件到`/usr/local/`目录下

```shell
sudo tar -zxvf hadoop-2.6.5.tar.gz -C /usr/local
```

重命名并修改权限：

```shell
cd /usr/local
sudo mv ./hadoop-2.6.5/ ./hadoop
sudo chown -R konfuse /hadoop
```

加入环境变量，在`/etc/profile`文件中加入hadoop的PATH：

```shell
# set hadoop environment
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

刷新当前环境，或重启计算机：

```shell
source /etc/profile
```

### 2.1 伪分布式配置：

伪分布式需要配置`/usr/local/hadoop/etc/hadoop`下的三个配置文件：

1. `hadoop-env.sh`配置

在其中加入计算机当前的Java环境：

```shell
# The java implementation to use.
export JAVA_HOME=/usr/java/jdk1.8.0_201
```

2. `core-site.xml`配置

vim打开文件，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/usr/local/hadoop/tmp</value>
        </property>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://localhost:9000</value>
        </property>
</configuration>
```

说明：可以看到这里使用的是`hdfs://localhost:9000`的hdfs文件系统，其它还有淘宝的`tfs://`，谷歌的`gfs://`以及本地的`file://`。

3. `hdfs-site.xml`配置

vim打开文件，在`<configuration></configuration>`中添加如下配置：

```xml
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
               <name>dfs.namenode.name.dir</name>
               <value>/usr/local/hadoop/tmp/dfs/name</value>
        </property>
        <property>
               <name>dfs.datanode.data.dir</name>
               <value>/usr/local/hadoop/tmp/dfs/data</value>
        </property>
</configuration>
```

其中，`dfs.replication`指的是文件的备份数。

**配置说明：** 

- Hadoop的运行方式由配置文件决定，Hadoop运行时会读取配置文件，因此删除`core-site.xml`中的配置项，就可以从伪分布模式切换到非分布式模式。
- 官方教程中，伪分布式只需要配置`fs.defaultFS`和`dfs.replication`就可以运行，但是默认使用的临时目录为`/tmp/hadoop-hadoop`，而这个目录在重启时有可能被系统清理掉，导致必须重新执行format才行。
- 所以实际使用需要配置`hadoop.tmp.dir`，`dfs.namenode.name.dir`和`dfs.datanode.data.dir`。

配置成功，启动hadoop之前需要对namenode进行初始化：

```shell
hdfs namenode -format
```

然后开启NameNode和DatNode进程：

```shell
start-dfs.sh
```

**注意：** 每次使用`hdfs namenode -format`命令进行初始化时，都会为NameNode生成新的namespaceID，但是在目录`hadoop.tmp.dir`中还是保留上次的namespaceID，若namespaceID不一致，则DataNode无法启动。所以需要删除目录`/usr/local/hadoop/tmp/dfs`下的data，重新生成datanode。

关闭Hadoop：

```shell
stop-dfs.sh
```

### 2.1 集群配置：

