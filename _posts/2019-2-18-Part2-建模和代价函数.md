# Part2 建模和代价函数

### 1. 符号定义

$$
x^{(i)}表示输入变量，也称为输入特征。\\
y^{(i)}表示输出或目标变量，也是我们需要预测的变量。\\
(x^{(i)}, y^{(i)})被称为一个训练样本\\
(x^{(i)}, y^{(i)}) ;i=1,..m被称为一个训练集合，用于训练\\
X表示输入变量空间\\
Y表示输出变量空间
$$

### 2. 监督学习的模型

监督学习中，我们的目标是利用一个训练集，学习出一个函数h，完成从输入空间X到输出空间Y的映射，而且h(x)的值可以很好的预测出y的值，过去函数h也可以称为一个假设。

- 当尝试去预测的目标变量是一个连续的值，例如房价预测问题，这是一个回归问题。
- 当y值只是一系列离散的值，就变成了一个分类问题。

在房价预测问题中，我们根据时间预测房价，用一条二维直线来作为学习模型，假设函数为：
$$
h_{\theta}(x) = \theta_{0} + \theta_{1}*x
$$


### 3. 代价函数

我们可以利用代价函数度量学习所得到的假设函数的准确性。代价函数即
$$
J(\theta_{0}, \theta_{1}) = \frac{1}{2m}\sum_{i=1}^{m}(\hat{y_{i}-y_{i}})^2 = \frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x_{i})-y_{i})^2
$$

这个函数也被称为平方误差函数，或者平均方差。均值变为一半以便梯度下降，因为平方函数的导数项会抵消1/2。

在房价预测问题中，我们的目标是得到一个最完美的线，这条线能够使得代价函数取得最小值。如果这条线穿过了训练集中所有的点，那么代价函数的值将为0。